{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPYMz70xz0f7h8jSWjo3ayS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vincenzodentamaro/keras-FastKAN/blob/main/Fast_Kan_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKpdECtdMrIY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ce90dc8-3559-4527-bccf-339d03a09f32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "Start of epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7e4a4cfa4160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7e4a4cfa4160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss (for one batch) at step 0: 2.5073800086975098\n",
            "Seen so far: 64 samples\n",
            "Training loss (for one batch) at step 200: 1.3673475980758667\n",
            "Seen so far: 12864 samples\n",
            "Training loss (for one batch) at step 400: 0.6204124689102173\n",
            "Seen so far: 25664 samples\n",
            "Training loss (for one batch) at step 600: 1.4972189664840698\n",
            "Seen so far: 38464 samples\n",
            "Training loss (for one batch) at step 800: 0.8662940859794617\n",
            "Seen so far: 51264 samples\n",
            "Training loss (for one batch) at step 1000: 0.758224606513977\n",
            "Seen so far: 64064 samples\n",
            "Training loss (for one batch) at step 1200: 0.033305682241916656\n",
            "Seen so far: 76864 samples\n",
            "Training loss (for one batch) at step 1400: 1.0611724853515625\n",
            "Seen so far: 89664 samples\n",
            "Training loss (for one batch) at step 1600: 2.479414463043213\n",
            "Seen so far: 102464 samples\n",
            "Training loss (for one batch) at step 1800: 0.510697603225708\n",
            "Seen so far: 115264 samples\n",
            "Training loss (for one batch) at step 2000: 3.2079367637634277\n",
            "Seen so far: 128064 samples\n",
            "Training loss (for one batch) at step 2200: 1.9940112829208374\n",
            "Seen so far: 140864 samples\n",
            "Training loss (for one batch) at step 2400: 0.1573210507631302\n",
            "Seen so far: 153664 samples\n",
            "Training loss (for one batch) at step 2600: 0.824654757976532\n",
            "Seen so far: 166464 samples\n",
            "Training loss (for one batch) at step 2800: 0.6494628190994263\n",
            "Seen so far: 179264 samples\n",
            "Training loss (for one batch) at step 3000: 1.1764875650405884\n",
            "Seen so far: 192064 samples\n",
            "Training loss (for one batch) at step 3200: 1.2004355192184448\n",
            "Seen so far: 204864 samples\n",
            "Training loss (for one batch) at step 3400: 0.13851650059223175\n",
            "Seen so far: 217664 samples\n",
            "Training loss (for one batch) at step 3600: 0.7970864772796631\n",
            "Seen so far: 230464 samples\n",
            "Training loss (for one batch) at step 3800: 0.18207122385501862\n",
            "Seen so far: 243264 samples\n",
            "Training loss (for one batch) at step 4000: 0.13851629197597504\n",
            "Seen so far: 256064 samples\n",
            "Training loss (for one batch) at step 4200: 0.9157738089561462\n",
            "Seen so far: 268864 samples\n",
            "Training loss (for one batch) at step 4400: 1.1362510919570923\n",
            "Seen so far: 281664 samples\n",
            "Training loss (for one batch) at step 4600: 3.692492723464966\n",
            "Seen so far: 294464 samples\n",
            "Training loss (for one batch) at step 4800: 1.4054726362228394\n",
            "Seen so far: 307264 samples\n",
            "Training loss (for one batch) at step 5000: 1.4721879959106445\n",
            "Seen so far: 320064 samples\n",
            "Training loss (for one batch) at step 5200: 0.66069495677948\n",
            "Seen so far: 332864 samples\n",
            "Training loss (for one batch) at step 5400: 1.6362147331237793\n",
            "Seen so far: 345664 samples\n",
            "Training loss (for one batch) at step 5600: 0.3543308675289154\n",
            "Seen so far: 358464 samples\n",
            "Training loss (for one batch) at step 5800: 5.501143932342529\n",
            "Seen so far: 371264 samples\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import optimizers, losses\n",
        "\n",
        "class RadialBasisFunction(layers.Layer):\n",
        "    def __init__(self, grid_min, grid_max, num_grids, **kwargs):\n",
        "        super(RadialBasisFunction, self).__init__(**kwargs)\n",
        "\n",
        "        self.grid = tf.cast(\n",
        "            tf.linspace(grid_min, grid_max, num_grids),\n",
        "            dtype=tf.float32,\n",
        "        )\n",
        "        self.denominator = tf.cast(\n",
        "            (grid_max - grid_min) / num_grids,\n",
        "            dtype=tf.float32,\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "        return tf.exp(-((x[..., None] - self.grid) / self.denominator) ** 2)\n",
        "\n",
        "class FastKANLayer(layers.Layer):\n",
        "    def __init__(self, input_dim, output_dim, grid_min, grid_max, num_grids, use_base_update, base_activation, spline_weight_init_scale):\n",
        "        super(FastKANLayer, self).__init__()\n",
        "        self.norm = layers.LayerNormalization(axis=-1)\n",
        "        self.rbf = RadialBasisFunction(grid_min, grid_max, num_grids)\n",
        "        self.spline_linear = layers.Dense(output_dim)\n",
        "        self.use_base_update = use_base_update\n",
        "        if use_base_update:\n",
        "            self.base_activation = base_activation\n",
        "            self.base_linear = layers.Dense(output_dim)\n",
        "    def call(self, x):\n",
        "        x_norm = self.norm(x)\n",
        "        spline_basis = self.rbf(x_norm)\n",
        "        spline_basis_flat = tf.reshape(spline_basis, [tf.shape(spline_basis)[0], -1])\n",
        "        ret = self.spline_linear(spline_basis_flat)\n",
        "        if self.use_base_update:\n",
        "            base = self.base_linear(self.base_activation(x))\n",
        "            ret = ret + base\n",
        "        return ret\n",
        "class FastKAN(tf.keras.Model):\n",
        "    def __init__(self, layers_hidden, grid_min=-1, grid_max=1, num_grids=10, use_base_update=False, base_activation='relu', spline_weight_init_scale=1):\n",
        "        super(FastKAN, self).__init__()\n",
        "        self.layers_list = []\n",
        "        for in_dim, out_dim in zip(layers_hidden[:-1], layers_hidden[1:]):\n",
        "            self.layers_list.append(FastKANLayer(in_dim, out_dim, grid_min, grid_max, num_grids, use_base_update, base_activation, spline_weight_init_scale))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.layers_list:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "# Load MNIST\n",
        "(train_images, train_labels), (val_images, val_labels) = mnist.load_data()\n",
        "train_images, val_images = train_images / 255.0, val_images / 255.0\n",
        "\n",
        "# Reshape the images to 1D arrays and convert to float32\n",
        "train_images = train_images.reshape((-1, 28*28)).astype('float32')\n",
        "val_images = val_images.reshape((-1, 28*28)).astype('float32')\n",
        "\n",
        "# Convert the labels to numpy arrays\n",
        "train_labels = np.array(train_labels)\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "# Define model\n",
        "model = FastKAN([28 * 28, 64, 10])\n",
        "\n",
        "# Define optimizer, loss and accuracy metric\n",
        "optimizer = optimizers.Adam(learning_rate=1e-3)\n",
        "loss_fn = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "# Train and validate for 20 epochs\n",
        "for epoch in range(20):\n",
        "    print(f'Start of epoch {epoch+1}')\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step in range(len(train_images)):\n",
        "        x_batch_train = train_images[step]\n",
        "        y_batch_train = train_labels[step]\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(x_batch_train[None, ...])\n",
        "            loss_value = loss_fn(y_batch_train[None, ...], logits)\n",
        "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "        # Update training metric.\n",
        "        accuracy_metric.update_state(y_batch_train[None, ...], logits)\n",
        "\n",
        "        # Log every 200 batches.\n",
        "        if step % 200 == 0:\n",
        "            print(f'Training loss (for one batch) at step {step}: {float(loss_value)}')\n",
        "            print(f'Seen so far: {(step + 1) * 64} samples')\n",
        "\n",
        "    # Display metrics at the end of each epoch.\n",
        "    train_acc = accuracy_metric.result()\n",
        "    print(f'Training acc over epoch: {float(train_acc)}')\n",
        "\n",
        "    # Reset training metrics at the end of each epoch\n",
        "    accuracy_metric.reset_states()\n",
        "\n",
        "    # Run a validation loop at the end of each epoch.\n",
        "    for step in range(len(val_images)):\n",
        "        x_batch_val = val_images[step]\n",
        "        y_batch_val = val_labels[step]\n",
        "        val_logits = model(x_batch_val[None, ...])\n",
        "        val_loss_value = loss_fn(y_batch_val[None, ...], val_logits)\n",
        "        # Update val metrics\n",
        "        accuracy_metric.update_state(y_batch_val[None, ...], val_logits)\n",
        "    val_acc = accuracy_metric.result()\n",
        "    accuracy_metric.reset_states()\n",
        "    print(f'Validation acc: {float(val_acc)}')\n"
      ]
    }
  ]
}